{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-06 10:28:00.161684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 10:28:00.309435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-06 10:28:00.309459: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-06 10:28:01.053118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 10:28:01.053192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 10:28:01.053201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "from src.models import metrics\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()\n",
    "accuracy = metrics.Accuracy()\n",
    "# print(gin.config_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hand_hypertuning(\n",
    "    learning_rates,\n",
    "    kernel_sizes,\n",
    "    filters1,\n",
    "    filters2,\n",
    "    units1,\n",
    "    units2,\n",
    "    model_dic,\n",
    "    epoch = 3,\n",
    "    num_classes = 10,\n",
    "    log_dir = \"../../models/test/\"):\n",
    "  \n",
    "    # make list if not list:\n",
    "    def make_ls(x):\n",
    "        return x if type(x) == type([]) else [x]\n",
    "\n",
    "    # maak van loopers list if not:\n",
    "    learning_rates = make_ls(learning_rates) \n",
    "    kernel_sizes = make_ls(kernel_sizes) \n",
    "    filters1 = make_ls(filters1) \n",
    "    filters2 = make_ls(filters2) \n",
    "    units1 = make_ls(units1) \n",
    "    units2 = make_ls(units2)\n",
    "\n",
    "    #model naam en model object vullen:\n",
    "    model_name = model_dic[0]\n",
    "    \n",
    "    \n",
    "    #gin_config resetten en vullen:\n",
    "    gin.clear_config()\n",
    "    gin.parse_config_file(\"model.gin\")\n",
    "    \n",
    "    gin.bind_parameter(\"trainloop.log_dir\",log_dir)\n",
    "    gin.bind_parameter(\"trainloop.epochs\", epoch)\n",
    "    gin.bind_parameter(model_name + '.num_classes', num_classes)\n",
    "    # gin.bind_parameter(model_name + '.kernel_size', kernel_size)\n",
    "\n",
    "    for fl1 in filters1:\n",
    "        for fl2 in filters2:\n",
    "            if fl2 <= fl1:\n",
    "                for ut1 in units1:\n",
    "                    for ut2 in units2:\n",
    "                        if ut2 <= ut1:\n",
    "                            for lr in learning_rates:\n",
    "                                for kerz in kernel_sizes:\n",
    "                                    \n",
    "                                    # pm_dic = {\n",
    "                                    #     fl1 : model_name + '.filter1'\n",
    "                                    #     ,fl2 : model_name + '.filter2'\n",
    "                                    #     ,ut1 : model_name + '.unit1'\n",
    "                                    #     ,ut2 : model_name + '.unit2'\n",
    "                                    #     ,kerz : model_name + '.kernel_size'\n",
    "                                    #     ,lr : 'trainloop.learning_rate'\n",
    "                                    # }\n",
    "                                    # print(pm_dic)\n",
    "                                    # for pm in pm_dic:\n",
    "                                    #     print(pm)\n",
    "                                    #     print(pm_dic[pm])\n",
    "                                    #     gin.bind_parameter(pm_dic[pm],pm)\n",
    "\n",
    "\n",
    "                                \n",
    "                                    gin.bind_parameter(model_name + '.filter1', fl1)\n",
    "                                    gin.bind_parameter(model_name + '.filter2', fl2)\n",
    "                                    gin.bind_parameter(model_name + '.unit1', ut1)\n",
    "                                    gin.bind_parameter(model_name + '.unit2', ut2)\n",
    "                                    gin.bind_parameter(model_name + '.kernel_size', kerz)\n",
    "                                    gin.bind_parameter(\"trainloop.learning_rate\", lr)\n",
    "                                    # print(gin.config_str())\n",
    "\n",
    "                                    model = model_dic[1]\n",
    "\n",
    "                                    model =  train_model.trainloop(\n",
    "                                        model=model(),\n",
    "                                        metrics=[accuracy],\n",
    "                                        train_dataloader=train_dataloader,\n",
    "                                        test_dataloader=test_dataloader,\n",
    "                                        train_steps=len(train_dataloader),\n",
    "                                        eval_steps=150,\n",
    "                                    )\n",
    "    \n",
    "    return None\n",
    "\n",
    "model_dic = {\n",
    "    'CNN':{0:'CNN',1:imagemodels.CNN}\n",
    "    ,'CNN_150': {0:'CNN_150',1:imagemodels.CNN_150}\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als eerste wordt de learning rate getest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 10:38:51.590 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/learning_rate/20230106-1038\n",
      "100%|██████████| 1875/1875 [01:17<00:00, 24.29it/s]\n",
      "2023-01-06 10:40:11.806 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6659 test 0.5314 metric ['0.7990']\n",
      "100%|██████████| 1875/1875 [01:17<00:00, 24.23it/s]\n",
      "2023-01-06 10:41:31.977 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.5046 test 0.5301 metric ['0.8113']\n",
      "100%|██████████| 1875/1875 [01:17<00:00, 24.34it/s]\n",
      "2023-01-06 10:42:51.782 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.4659 test 0.5733 metric ['0.8042']\n",
      "100%|██████████| 1875/1875 [01:18<00:00, 24.03it/s]\n",
      "2023-01-06 10:44:12.581 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.4629 test 0.4998 metric ['0.8260']\n",
      "100%|██████████| 1875/1875 [01:16<00:00, 24.53it/s]\n",
      "2023-01-06 10:45:31.941 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.4569 test 0.4934 metric ['0.8252']\n",
      " 68%|██████▊   | 1273/1875 [00:51<00:24, 24.65it/s]\n",
      " 50%|█████     | 5/10 [07:31<07:31, 90.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hand_hypertuning(\n\u001b[1;32m      2\u001b[0m     model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m     ,learning_rates \u001b[39m=\u001b[39;49m [\u001b[39m0.01\u001b[39;49m, \u001b[39m0.001\u001b[39;49m, \u001b[39m0.0001\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m     ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      5\u001b[0m     ,filters1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      6\u001b[0m     ,filters2 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      7\u001b[0m     ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     ,units2 \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m\n\u001b[1;32m      9\u001b[0m     ,epoch \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m\n\u001b[1;32m     10\u001b[0m     ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/learning_rate/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/transforms/functional.py:153\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    151\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(pic\u001b[39m.\u001b[39mgetbands()))\n\u001b[1;32m    152\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN']\n",
    "    ,learning_rates = [0.01, 0.001, 0.0001]\n",
    "    ,kernel_sizes = 2\n",
    "    ,filters1 = 128\n",
    "    ,filters2 = 128\n",
    "    ,units1 = 128\n",
    "    ,units2 = 64\n",
    "    ,epoch = 10\n",
    "    ,log_dir = \"../../models/learning_rate/\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we weten dat de optimale learning rate ligt op ongeveer 0.001 kan verder naar andere optimuns worden gezocht.\n",
    "Als eerste wordt kernelsize getest:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernal; size is optimaal op 2 omdat filters en units de onformatie aan elkaar doorgeven, hebben filter zise en unitr een invloed op elkaar. De units nemen het over op een platten 128. dit geeft beperkingen deze zijn meegenomen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 10:46:26.459 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters/20230106-1046\n",
      "100%|██████████| 1875/1875 [00:22<00:00, 82.06it/s]\n",
      "2023-01-06 10:46:50.307 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.7647 test 0.5769 metric ['0.7887']\n",
      "100%|██████████| 1875/1875 [00:22<00:00, 83.24it/s]\n",
      "2023-01-06 10:47:13.687 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.5297 test 0.5126 metric ['0.8117']\n",
      "100%|██████████| 1875/1875 [00:22<00:00, 83.03it/s]\n",
      "2023-01-06 10:47:37.124 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.4653 test 0.4550 metric ['0.8367']\n",
      "100%|██████████| 3/3 [01:10<00:00, 23.51s/it]\n",
      "2023-01-06 10:47:37.130 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters/20230106-1047\n",
      "100%|██████████| 1875/1875 [00:27<00:00, 68.41it/s]\n",
      "2023-01-06 10:48:05.817 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.7111 test 0.5777 metric ['0.7819']\n",
      "100%|██████████| 1875/1875 [00:28<00:00, 66.65it/s]\n",
      "2023-01-06 10:48:35.197 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.4872 test 0.4727 metric ['0.8323']\n",
      " 48%|████▊     | 906/1875 [00:13<00:14, 67.18it/s]\n",
      " 67%|██████▋   | 2/3 [01:11<00:35, 35.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fil_range_e10 \u001b[39m=\u001b[39m ([\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m],\u001b[39m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39min\u001b[39;00m [fil_range_e3,fil_range_e10]:\n\u001b[0;32m----> 5\u001b[0m     hand_hypertuning(\n\u001b[1;32m      6\u001b[0m         model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      7\u001b[0m         ,learning_rates \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m\n\u001b[1;32m      8\u001b[0m         ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      9\u001b[0m         ,filters1 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     10\u001b[0m         ,filters2 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     11\u001b[0m         ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     12\u001b[0m         ,units2 \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m\n\u001b[1;32m     13\u001b[0m         ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/filters/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m         ,epoch \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     15\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_iterator\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_BaseDataLoaderIter\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[39mreturn\u001b[39;00m _SingleProcessDataLoaderIter(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    388\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:712\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[0;32m--> 712\u001b[0m     \u001b[39msuper\u001b[39;49m(_SingleProcessDataLoaderIter, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(loader)\n\u001b[1;32m    713\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    714\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collate_fn \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mcollate_fn\n\u001b[1;32m    651\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_sampler)\n\u001b[0;32m--> 652\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_seed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mempty((), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64)\u001b[39m.\u001b[39;49mrandom_(generator\u001b[39m=\u001b[39;49mloader\u001b[39m.\u001b[39;49mgenerator)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mpersistent_workers\n\u001b[1;32m    654\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fil_range_e3 = ([16,32,64,128],3)\n",
    "fil_range_e10 = ([32,64],10)\n",
    "\n",
    "for list in [fil_range_e3,fil_range_e10]:\n",
    "    hand_hypertuning(\n",
    "        model_dic = model_dic['CNN']\n",
    "        ,learning_rates = 0.001\n",
    "        ,kernel_sizes = 2\n",
    "        ,filters1 = list[0]\n",
    "        ,filters2 = list[0]\n",
    "        ,units1 = 128\n",
    "        ,units2 = 64\n",
    "        ,log_dir = \"../../models/filters/\"\n",
    "        ,epoch = list[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 10:49:33.838 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/units/20230106-1049\n",
      "100%|██████████| 1875/1875 [00:42<00:00, 44.04it/s]\n",
      "2023-01-06 10:50:18.313 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.8018 test 0.6248 metric ['0.7708']\n",
      " 37%|███▋      | 689/1875 [00:15<00:26, 45.17it/s]\n",
      " 33%|███▎      | 1/3 [00:59<01:59, 59.57s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m unit_range_e10 \u001b[39m=\u001b[39m ([\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m],\u001b[39m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39min\u001b[39;00m [unit_range_e3,unit_range_e10]:\n\u001b[0;32m----> 5\u001b[0m     hand_hypertuning(\n\u001b[1;32m      6\u001b[0m         model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      7\u001b[0m         ,learning_rates \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m\n\u001b[1;32m      8\u001b[0m         ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      9\u001b[0m         ,filters1 \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m\n\u001b[1;32m     10\u001b[0m         ,filters2 \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m\n\u001b[1;32m     11\u001b[0m         ,units1 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     12\u001b[0m         ,units2 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     13\u001b[0m         ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/units/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m         ,epoch \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     15\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unit_range_e3 = ([16,32,64,128],3)\n",
    "unit_range_e10 = ([32,64,128],10)\n",
    "\n",
    "for list in [unit_range_e3,unit_range_e10]:\n",
    "    hand_hypertuning(\n",
    "        model_dic = model_dic['CNN']\n",
    "        ,learning_rates = 0.001\n",
    "        ,kernel_sizes = 2\n",
    "        ,filters1 = 64\n",
    "        ,filters2 = 64\n",
    "        ,units1 = list[0]\n",
    "        ,units2 = list[0]\n",
    "        ,log_dir = \"../../models/units/\"\n",
    "        ,epoch = list[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 10:51:04.307 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20230106-1051\n",
      "100%|██████████| 1875/1875 [00:25<00:00, 72.47it/s]\n",
      "2023-01-06 10:51:31.288 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.8002 test 0.5733 metric ['0.7833']\n",
      "100%|██████████| 1875/1875 [00:26<00:00, 72.10it/s]\n",
      "2023-01-06 10:51:58.219 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.4938 test 0.4948 metric ['0.8140']\n",
      "100%|██████████| 1875/1875 [00:26<00:00, 71.08it/s]\n",
      "2023-01-06 10:52:25.531 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.4152 test 0.4027 metric ['0.8512']\n",
      "100%|██████████| 3/3 [01:21<00:00, 27.02s/it]\n",
      "2023-01-06 10:52:25.538 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20230106-1052\n",
      " 96%|█████████▌| 1793/1875 [00:31<00:01, 56.98it/s]\n",
      "  0%|          | 0/3 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fil_range_e10 \u001b[39m=\u001b[39m ([\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m],\u001b[39m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39min\u001b[39;00m [fil_range_e3,fil_range_e10]:\n\u001b[0;32m----> 5\u001b[0m     hand_hypertuning(\n\u001b[1;32m      6\u001b[0m         model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN_150\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      7\u001b[0m         ,learning_rates \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m\n\u001b[1;32m      8\u001b[0m         ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      9\u001b[0m         ,filters1 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     10\u001b[0m         ,filters2 \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     11\u001b[0m         ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     12\u001b[0m         ,units2 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     13\u001b[0m         ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/filters_cnn150/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m         ,epoch \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     15\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/transforms/functional.py:151\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[0;32m--> 151\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], \u001b[39mlen\u001b[39;49m(pic\u001b[39m.\u001b[39;49mgetbands()))\n\u001b[1;32m    152\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    153\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fil_range_e3 = ([16,32,64,128],3)\n",
    "fil_range_e10 = ([32,64],10)\n",
    "\n",
    "for list in [fil_range_e3,fil_range_e10]:\n",
    "    hand_hypertuning(\n",
    "        model_dic = model_dic['CNN_150']\n",
    "        ,learning_rates = 0.001\n",
    "        ,kernel_sizes = 2\n",
    "        ,filters1 = list[0]\n",
    "        ,filters2 = list[0]\n",
    "        ,units1 = 64\n",
    "        ,units2 = 64\n",
    "        ,log_dir = \"../../models/filters_cnn150/\"\n",
    "        ,epoch = list[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_unit_e3 = ([16,32,64,128,256],3)\n",
    "fil_unit_e10 = ([32,64,128],10)\n",
    "\n",
    "for list in [fil_unit_e3,fil_unit_e10]:\n",
    "    hand_hypertuning(\n",
    "        model_dic = model_dic['CNN_150']\n",
    "        ,learning_rates = 0.001\n",
    "        ,kernel_sizes = 2\n",
    "        ,filters1 = 64\n",
    "        ,filters2 = 32\n",
    "        ,units1 = list[0]\n",
    "        ,units2 = list[0]\n",
    "        ,log_dir = \"../../models/units_cnn150/\"\n",
    "        ,epoch = list[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('poetry_add_pandas-Tn0MmM9i-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc99aa1bd7537e0258e13e20cc216861e02369acc2d56ce5faa223331cf95d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
