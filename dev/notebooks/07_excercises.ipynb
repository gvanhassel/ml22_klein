{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-12 18:04:44.012485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 18:04:44.220846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 18:04:44.220880: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 18:04:44.999348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 18:04:44.999442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 18:04:44.999451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "from src.models import metrics\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()\n",
    "accuracy = metrics.Accuracy()\n",
    "# print(gin.config_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hand_hypertuning(\n",
    "    learning_rates,\n",
    "    kernel_sizes,\n",
    "    filters1,\n",
    "    filters2,\n",
    "    units1,\n",
    "    units2,\n",
    "    model_dic,\n",
    "    epoch = 3,\n",
    "    num_classes = 10,\n",
    "    log_dir = \"../../models/test/\"):\n",
    "  \n",
    "    # make list if not list:\n",
    "    def make_ls(x):\n",
    "        return x if type(x) == type([]) else [x]\n",
    "\n",
    "    # maak van loopers list if not:\n",
    "    learning_rates = make_ls(learning_rates) \n",
    "    kernel_sizes = make_ls(kernel_sizes) \n",
    "    filters1 = make_ls(filters1) \n",
    "    filters2 = make_ls(filters2) \n",
    "    units1 = make_ls(units1) \n",
    "    units2 = make_ls(units2)\n",
    "\n",
    "    #model naam en model object vullen:\n",
    "    \n",
    "    model_name = model_dic[0]\n",
    "    \n",
    "    \n",
    "    #gin_config resetten en vullen:\n",
    "    gin.clear_config()\n",
    "    gin.parse_config_file(\"model.gin\")\n",
    "    \n",
    "    gin.bind_parameter(\"trainloop.log_dir\",log_dir)\n",
    "    gin.bind_parameter(\"trainloop.epochs\", epoch)\n",
    "    gin.bind_parameter(model_name + '.num_classes', num_classes)\n",
    "    # gin.bind_parameter(model_name + '.kernel_size', kernel_size)\n",
    "\n",
    "    for fl1 in filters1:\n",
    "        for fl2 in filters2:\n",
    "            if fl2 <= fl1:\n",
    "                for ut1 in units1:\n",
    "                    for ut2 in units2:\n",
    "                        if ut2 <= ut1:\n",
    "                            for lr in learning_rates:\n",
    "                                for kerz in kernel_sizes:\n",
    "                                \n",
    "                                    gin.bind_parameter(model_name + '.filter1', fl1)\n",
    "                                    gin.bind_parameter(model_name + '.filter2', fl2)\n",
    "                                    gin.bind_parameter(model_name + '.unit1', ut1)\n",
    "                                    gin.bind_parameter(model_name + '.unit2', ut2)\n",
    "                                    gin.bind_parameter(model_name + '.kernel_size', kerz)\n",
    "                                    gin.bind_parameter(\"trainloop.learning_rate\", lr)\n",
    "                                    # print(gin.config_str())\n",
    "\n",
    "                                    model = model_dic[1]\n",
    "\n",
    "                                    model =  train_model.trainloop(\n",
    "                                        model=model(),\n",
    "                                        metrics=[accuracy],\n",
    "                                        train_dataloader=train_dataloader,\n",
    "                                        test_dataloader=test_dataloader,\n",
    "                                        train_steps=len(train_dataloader),\n",
    "                                        eval_steps=150,\n",
    "                                    )\n",
    "    \n",
    "    return None\n",
    "\n",
    "model_dic = {\n",
    "    'CNN':{0:'CNN',1:imagemodels.CNN}\n",
    "    ,'CNN_150': {0:'CNN_150',1:imagemodels.CNN_150}\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als eerste wordt de learning rate getest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hand_hypertuning(\n",
    "#     model_dic = model_dic['CNN']\n",
    "#     ,learning_rates = [0.01, 0.001, 0.0001]\n",
    "#     ,kernel_sizes = 3\n",
    "#     ,filters1 = 128\n",
    "#     ,filters2 = 128\n",
    "#     ,units1 = 128\n",
    "#     ,units2 = 64\n",
    "#     ,log_dir = \"../../models/learning_rate/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we weten dat de optimale learning rate ligt op ongeveer 0.001 kan verder naar andere optimuns worden gezocht.\n",
    "Als eerste wordt kernelsize getest:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernal; size is optimaal op 2 omdat filters en units de onformatie aan elkaar doorgeven, hebben filter zise en unitr een invloed op elkaar. De units nemen het over op een platten 128. dit geeft beperkingen deze zijn meegenomen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fil_range_e3 = [16,32,64,128]\n",
    "# fil_range_e10 = [32,64]\n",
    "\n",
    "# hand_hypertuning(\n",
    "#     model_dic = model_dic['CNN']\n",
    "#     ,learning_rates = 0.001\n",
    "#     ,kernel_sizes = 2\n",
    "#     ,filters1 = fil_range_e10\n",
    "#     ,filters2 = fil_range_e10\n",
    "#     ,units1 = 128\n",
    "#     ,units2 = 64\n",
    "#     ,log_dir = \"../../models/filters/\"\n",
    "#     ,epoch = 10\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_range_e3 = [16,32,64,128]\n",
    "unit_range_e10 = [32,64,128]\n",
    "\n",
    "# hand_hypertuning(\n",
    "#     model_dic = model_dic['CNN']\n",
    "#     ,learning_rates = 0.001\n",
    "#     ,kernel_sizes = 2\n",
    "#     ,filters1 = 64\n",
    "#     ,filters2 = 64\n",
    "#     ,units1 = 128\n",
    "#     ,units2 = 128\n",
    "#     ,log_dir = \"../../models/units/\"\n",
    "#     ,epoch = 3\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:04:50.019 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20221212-1804\n",
      "100%|██████████| 1875/1875 [00:31<00:00, 58.85it/s]\n",
      "2022-12-12 18:05:23.458 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.7634 test 0.5661 metric ['0.7758']\n",
      "100%|██████████| 1875/1875 [00:30<00:00, 61.04it/s]\n",
      "2022-12-12 18:05:55.181 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.4487 test 0.4155 metric ['0.8321']\n",
      "100%|██████████| 1875/1875 [00:30<00:00, 62.15it/s]\n",
      "2022-12-12 18:06:26.383 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.3783 test 0.4050 metric ['0.8473']\n",
      "100%|██████████| 3/3 [01:35<00:00, 31.95s/it]\n",
      "2022-12-12 18:06:26.390 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20221212-1806\n",
      "100%|██████████| 1875/1875 [00:37<00:00, 49.65it/s]\n",
      "2022-12-12 18:07:05.719 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6780 test 0.4466 metric ['0.8410']\n",
      "100%|██████████| 1875/1875 [00:38<00:00, 48.08it/s]\n",
      "2022-12-12 18:07:46.075 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.3881 test 0.3799 metric ['0.8621']\n",
      "100%|██████████| 1875/1875 [00:38<00:00, 48.67it/s]\n",
      "2022-12-12 18:08:25.982 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.3282 test 0.3556 metric ['0.8758']\n",
      "100%|██████████| 3/3 [01:59<00:00, 39.80s/it]\n",
      "2022-12-12 18:08:25.989 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20221212-1808\n",
      " 96%|█████████▋| 1805/1875 [00:36<00:01, 49.14it/s]\n",
      "  0%|          | 0/3 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fil_range_e3 \u001b[39m=\u001b[39m [\u001b[39m16\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39m# fil_range_e10 = [32,64]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m hand_hypertuning(\n\u001b[1;32m      5\u001b[0m     model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN_150\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m     ,learning_rates \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m\n\u001b[1;32m      7\u001b[0m     ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     ,filters1 \u001b[39m=\u001b[39;49m fil_range_e3\n\u001b[1;32m      9\u001b[0m     ,filters2 \u001b[39m=\u001b[39;49m fil_range_e3\n\u001b[1;32m     10\u001b[0m     ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     11\u001b[0m     ,units2 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     12\u001b[0m     ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/filters_cnn150/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m     ,epoch \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m\n\u001b[1;32m     14\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     56\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 58\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     59\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     60\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     61\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     62\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     63\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     64\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     65\u001b[0m                                 )\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:43\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     41\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 43\u001b[0m yhat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     44\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(yhat, y)\n\u001b[1;32m     45\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/imagemodels.py:93\u001b[0m, in \u001b[0;36mCNN_150.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 93\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolutions(x)\n\u001b[1;32m     94\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(x)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/modules/pooling.py:162\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    163\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    164\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/_jit_internal.py:423\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fil_range_e3 = [16,32,64,128]\n",
    "# fil_range_e10 = [32,64]\n",
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN_150']\n",
    "    ,learning_rates = 0.001\n",
    "    ,kernel_sizes = 2\n",
    "    ,filters1 = fil_range_e3\n",
    "    ,filters2 = fil_range_e3\n",
    "    ,units1 = 128\n",
    "    ,units2 = 128\n",
    "    ,log_dir = \"../../models/filters_cnn150/\"\n",
    "    ,epoch = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('poetry_add_pandas-Tn0MmM9i-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc99aa1bd7537e0258e13e20cc216861e02369acc2d56ce5faa223331cf95d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
