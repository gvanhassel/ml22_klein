{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-06 11:04:52.449946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 11:04:52.631159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 11:04:52.631185: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 11:04:53.596685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 11:04:53.596801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 11:04:53.596814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()\n",
    "# print(gin.config_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big advantage is that we can save this config as a file; that way it is easy to track what you changed during your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from src.models import metrics\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 11:27:38.219 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/units_padding_all1_kernal3_l288/20221206-1127\n",
      "100%|██████████| 1875/1875 [01:13<00:00, 25.41it/s]\n",
      "2022-12-06 11:28:54.757 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.5189 test 0.4561 metric ['0.8327']\n",
      "100%|██████████| 1875/1875 [01:09<00:00, 26.97it/s]\n",
      "2022-12-06 11:30:06.751 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.3211 test 0.3187 metric ['0.8821']\n",
      "100%|██████████| 1875/1875 [01:10<00:00, 26.68it/s]\n",
      "2022-12-06 11:31:19.521 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.2747 test 0.3180 metric ['0.8883']\n",
      "100%|██████████| 1875/1875 [01:10<00:00, 26.60it/s]\n",
      "2022-12-06 11:32:32.457 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.2373 test 0.2668 metric ['0.9054']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.27it/s]\n",
      "2022-12-06 11:33:43.594 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.2195 test 0.2670 metric ['0.9060']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.35it/s]\n",
      "2022-12-06 11:34:54.561 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.1992 test 0.2523 metric ['0.9081']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.53it/s]\n",
      "2022-12-06 11:36:05.342 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.1858 test 0.2574 metric ['0.9137']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.36it/s]\n",
      "2022-12-06 11:37:16.328 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.1715 test 0.2557 metric ['0.9142']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.56it/s]\n",
      "2022-12-06 11:38:26.796 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.1590 test 0.2504 metric ['0.9165']\n",
      "100%|██████████| 1875/1875 [01:08<00:00, 27.33it/s]\n",
      "2022-12-06 11:39:37.871 | INFO     | src.models.train_model:trainloop:171 - Epoch 9 train 0.1471 test 0.2614 metric ['0.9113']\n",
      "100%|██████████| 1875/1875 [01:07<00:00, 27.60it/s]\n",
      "2022-12-06 11:40:48.207 | INFO     | src.models.train_model:trainloop:171 - Epoch 10 train 0.1385 test 0.2623 metric ['0.9187']\n",
      "100%|██████████| 1875/1875 [01:09<00:00, 27.10it/s]\n",
      "2022-12-06 11:41:59.798 | INFO     | src.models.train_model:trainloop:171 - Epoch 11 train 0.1317 test 0.2677 metric ['0.9129']\n",
      "100%|██████████| 12/12 [14:21<00:00, 71.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "\n",
    "learning_rates = [0.001] #[0.005, 0.001, 0.0005]\n",
    "kernel_sizes = [3] #[1,3,6,12] #default: 3\n",
    "filters1 = [64]#[16,32,64] #[24,28,32,40,48]#[16,32,64,128] #default: 32\n",
    "filters2 = [32]#[16,32,64] #[24,28,32,40,48]#[16,32,64,128] #default: 32\n",
    "units1 = [254] #[48,56,64,78,92] #[16,32,64,128]#default: 64\n",
    "units2 = [128]#[16,32,64] #[20,32,56] #[16,32,64,128]#default: 32\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "\n",
    "gin.bind_parameter(\"trainloop.log_dir\", \"../../models/units_padding_all1_kernal3_l288/\")\n",
    "\n",
    "gin.bind_parameter(\"CNN_padding1.num_classes\", num_classes)\n",
    "# gin.bind_parameter(\"CNN.kernel_size\", kernel_size)\n",
    "gin.bind_parameter(\"trainloop.epochs\", epoch)\n",
    "\n",
    "\n",
    "\n",
    "for fl1 in filters1:\n",
    "    for fl2 in filters2:\n",
    "        if fl2 <= fl1:\n",
    "            for ut1 in units1:\n",
    "                for ut2 in units2:\n",
    "                    if ut2 <= ut1:\n",
    "                        for lr in learning_rates:\n",
    "                            for kerz in kernel_sizes:\n",
    "\n",
    "                            \n",
    "                                gin.bind_parameter(\"CNN_padding1.filter1\", fl1)\n",
    "                                gin.bind_parameter(\"CNN_padding1.filter2\", fl2)\n",
    "                                gin.bind_parameter(\"CNN_padding1.unit1\", ut1)\n",
    "                                gin.bind_parameter(\"CNN_padding1.unit2\", ut2)\n",
    "                                gin.bind_parameter(\"CNN_padding1.kernel_size\", kerz)\n",
    "\n",
    "                                gin.bind_parameter(\"trainloop.learning_rate\", lr)\n",
    "\n",
    "                                model = imagemodels.CNN_padding1()\n",
    "                                model =  train_model.trainloop(\n",
    "                                    model=model,\n",
    "                                    metrics=[accuracy],\n",
    "                                    train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    train_steps=len(train_dataloader),\n",
    "                                    eval_steps=150,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3602976460.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    test 1\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test 1\n",
    "\n",
    "filter2 = [16,32,64,128,256]\n",
    "unit1 = [64,128,256,512,1024]\n",
    "\n",
    "resultaat optimaal:\n",
    "filter2 = [128]\n",
    "unit1 = [256]\n",
    "\n",
    "test 2\n",
    "\n",
    "filter2 = [64,..,..,..,..,128,..,..,256]\n",
    "unit1 = [64,..,..,..,128,..,..,..,..,256]\n",
    "\n",
    "resultaat optimaal:\n",
    "filter2 = [168]\n",
    "unit1 = [75]\n",
    "\n",
    "test 3\n",
    "\n",
    "filter2 = [64,..,..,..,..,128,..,..,256]\n",
    "unit1 = [64,..,..,..,128,..,..,..,..,256]\n",
    "\n",
    "resultaat optimaal:\n",
    "filter2 = [168]\n",
    "unit1 = [75]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, navigate to ~/code/ML22 \n",
    "- activate the python environment for the shell with `poetry shell`. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=models` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Experiment with things like:\n",
    "\n",
    "- changing the amount of units1 and units2 to values between 16 and 1024. Use factors of 2: 16, 32, 64, etc.\n",
    "- changing the batchsize to values between 4 and 128. Again, use factors of two.\n",
    "- all your experiments are saved in the `models` directory, with a timestamp. Inside you find a saved_config.gin file, that \n",
    "contains all the settings for that experiment. The `events` file is what tensorboard will show.\n",
    "- plot the result in a heatmap: units vs batchsize.\n",
    "- changing the learningrate to values between 1e-2 and 1e-5 \n",
    "- changing the optimizer from SGD to one of the other available algoritms at [torch](https://pytorch.org/docs/stable/optim.html) (scroll down for the algorithms)\n",
    "\n",
    "A note on train_steps: this is a setting that determines how often you get an update. \n",
    "Because our complete dataset is 938 (60000 / 64) batches long, you will need 938 trainstep to cover the complete 60.000 images.\n",
    "\n",
    "This can actually be a bit confusion, because every value below 938 changes the meaning of `epoch` slightly, because one epoch is no longer\n",
    "the full dataset, but simply `trainstep` batches. Setting trainsteps to 100 means you need to wait twice as long before you get feedback on the performance,\n",
    "as compared to trainsteps=50. You will also see that settings trainsteps to 100 improves the learning, but that is simply because the model has seen twice as \n",
    "much examples as compared to trainsteps=50.\n",
    "\n",
    "This implies that it is not usefull to compare trainsteps=50 and trainsteps=100, because setting it to 100 will always be better.\n",
    "Just pick an amount, and adjust your number of epochs accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('poetry_add_pandas-Tn0MmM9i-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc99aa1bd7537e0258e13e20cc216861e02369acc2d56ce5faa223331cf95d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
