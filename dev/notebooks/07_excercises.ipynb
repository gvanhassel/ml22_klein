{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-31 09:34:43.644217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-31 09:34:46.127226: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-31 09:34:46.127260: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-31 09:34:51.469124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-31 09:34:51.469362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-31 09:34:51.469376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/azureuser/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "from src.models import metrics\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()\n",
    "accuracy = metrics.Accuracy()\n",
    "# print(gin.config_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hand_hypertuning(\n",
    "    learning_rates,\n",
    "    kernel_sizes,\n",
    "    filters1,\n",
    "    filters2,\n",
    "    units1,\n",
    "    units2,\n",
    "    model_dic,\n",
    "    epoch = 3,\n",
    "    num_classes = 10,\n",
    "    log_dir = \"../../models/test/\"):\n",
    "  \n",
    "    # make list if not list:\n",
    "    def make_ls(x):\n",
    "        return x if type(x) == type([]) else [x]\n",
    "\n",
    "    # maak van loopers list if not:\n",
    "    learning_rates = make_ls(learning_rates) \n",
    "    kernel_sizes = make_ls(kernel_sizes) \n",
    "    filters1 = make_ls(filters1) \n",
    "    filters2 = make_ls(filters2) \n",
    "    units1 = make_ls(units1) \n",
    "    units2 = make_ls(units2)\n",
    "\n",
    "    #model naam en model object vullen:\n",
    "    model_name = model_dic[0]\n",
    "    \n",
    "    \n",
    "    #gin_config resetten en vullen:\n",
    "    gin.clear_config()\n",
    "    gin.parse_config_file(\"model.gin\")\n",
    "    \n",
    "    gin.bind_parameter(\"trainloop.log_dir\",log_dir)\n",
    "    gin.bind_parameter(\"trainloop.epochs\", epoch)\n",
    "    gin.bind_parameter(model_name + '.num_classes', num_classes)\n",
    "    # gin.bind_parameter(model_name + '.kernel_size', kernel_size)\n",
    "\n",
    "    for fl1 in filters1:\n",
    "        for fl2 in filters2:\n",
    "            if fl2 <= fl1:\n",
    "                for ut1 in units1:\n",
    "                    for ut2 in units2:\n",
    "                        if ut2 <= ut1:\n",
    "                            for lr in learning_rates:\n",
    "                                for kerz in kernel_sizes:\n",
    "                                    \n",
    "                                    # pm_dic = {\n",
    "                                    #     fl1 : model_name + '.filter1'\n",
    "                                    #     ,fl2 : model_name + '.filter2'\n",
    "                                    #     ,ut1 : model_name + '.unit1'\n",
    "                                    #     ,ut2 : model_name + '.unit2'\n",
    "                                    #     ,kerz : model_name + '.kernel_size'\n",
    "                                    #     ,lr : 'trainloop.learning_rate'\n",
    "                                    # }\n",
    "                                    # print(pm_dic)\n",
    "                                    # for pm in pm_dic:\n",
    "                                    #     print(pm)\n",
    "                                    #     print(pm_dic[pm])\n",
    "                                    #     gin.bind_parameter(pm_dic[pm],pm)\n",
    "\n",
    "\n",
    "                                \n",
    "                                    gin.bind_parameter(model_name + '.filter1', fl1)\n",
    "                                    gin.bind_parameter(model_name + '.filter2', fl2)\n",
    "                                    gin.bind_parameter(model_name + '.unit1', ut1)\n",
    "                                    gin.bind_parameter(model_name + '.unit2', ut2)\n",
    "                                    gin.bind_parameter(model_name + '.kernel_size', kerz)\n",
    "                                    gin.bind_parameter(\"trainloop.learning_rate\", lr)\n",
    "                                    # print(gin.config_str())\n",
    "\n",
    "                                    model = model_dic[1]\n",
    "\n",
    "                                    model =  train_model.trainloop(\n",
    "                                        model=model(),\n",
    "                                        metrics=[accuracy],\n",
    "                                        train_dataloader=train_dataloader,\n",
    "                                        test_dataloader=test_dataloader,\n",
    "                                        train_steps=len(train_dataloader),\n",
    "                                        eval_steps=150,\n",
    "                                    )\n",
    "    \n",
    "    return None\n",
    "\n",
    "model_dic = {\n",
    "    'CNN':{0:'CNN',1:imagemodels.CNN}\n",
    "    ,'CNN_150': {0:'CNN_150',1:imagemodels.CNN_150}\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als eerste wordt de learning rate getest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 12:45:15.170 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/test/20221229-1245\n",
      " 13%|█▎        | 252/1875 [00:15<01:37, 16.73it/s]\n",
      "  0%|          | 0/3 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hand_hypertuning(\n\u001b[1;32m      2\u001b[0m     model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m     ,learning_rates \u001b[39m=\u001b[39;49m [\u001b[39m0.01\u001b[39;49m, \u001b[39m0.001\u001b[39;49m, \u001b[39m0.0001\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m     ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m\n\u001b[1;32m      5\u001b[0m     ,filters1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      6\u001b[0m     ,filters2 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      7\u001b[0m     ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     ,units2 \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# ,log_dir = \"../../models/learning_rate/\"\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img\u001b[39m.\u001b[39;49mnumpy(), mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/PIL/Image.py:2982\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2943\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromarray\u001b[39m(obj, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2944\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \u001b[39m    Creates an image memory from an object exporting the array interface\u001b[39;00m\n\u001b[1;32m   2946\u001b[0m \u001b[39m    (using the buffer protocol).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[39m    .. versionadded:: 1.1.6\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m     arr \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m__array_interface__\n\u001b[1;32m   2983\u001b[0m     shape \u001b[39m=\u001b[39m arr[\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2984\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN']\n",
    "    ,learning_rates = [0.01, 0.001, 0.0001]\n",
    "    ,kernel_sizes = 3\n",
    "    ,filters1 = 128\n",
    "    ,filters2 = 128\n",
    "    ,units1 = 128\n",
    "    ,units2 = 64\n",
    "    ,epoch = 10\n",
    "    ,log_dir = \"../../models/learning_rate/\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we weten dat de optimale learning rate ligt op ongeveer 0.001 kan verder naar andere optimuns worden gezocht.\n",
    "Als eerste wordt kernelsize getest:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernal; size is optimaal op 2 omdat filters en units de onformatie aan elkaar doorgeven, hebben filter zise en unitr een invloed op elkaar. De units nemen het over op een platten 128. dit geeft beperkingen deze zijn meegenomen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_range_e3 = [16,32,64,128]\n",
    "fil_range_e10 = [32,64]\n",
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN']\n",
    "    ,learning_rates = 0.001\n",
    "    ,kernel_sizes = 3\n",
    "    ,filters1 = fil_range_e10\n",
    "    ,filters2 = fil_range_e10\n",
    "    ,units1 = 128\n",
    "    ,units2 = 64\n",
    "    ,log_dir = \"../../models/filters/\"\n",
    "    ,epoch = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_range_e3 = [16,32,64,128]\n",
    "unit_range_e10 = [32,64,128]\n",
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN']\n",
    "    ,learning_rates = 0.001\n",
    "    ,kernel_sizes = 3\n",
    "    ,filters1 = 64\n",
    "    ,filters2 = 64\n",
    "    ,units1 = 128\n",
    "    ,units2 = 128\n",
    "    ,log_dir = \"../../models/units/\"\n",
    "    ,epoch = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 09:34:58.413 | INFO     | src.data.data_tools:dir_add_timestamp:114 - Logging to ../../models/filters_cnn150/20221231-0934\n",
      "100%|██████████| 1875/1875 [00:56<00:00, 33.39it/s]\n",
      "2022-12-31 09:35:57.622 | INFO     | src.models.train_model:trainloop:171 - Epoch 0 train 0.6369 test 0.4305 metric ['0.8471']\n",
      "100%|██████████| 1875/1875 [00:54<00:00, 34.56it/s]\n",
      "2022-12-31 09:36:53.940 | INFO     | src.models.train_model:trainloop:171 - Epoch 1 train 0.3831 test 0.3645 metric ['0.8610']\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 33.93it/s]\n",
      "2022-12-31 09:37:51.348 | INFO     | src.models.train_model:trainloop:171 - Epoch 2 train 0.3261 test 0.3377 metric ['0.8740']\n",
      "100%|██████████| 1875/1875 [00:54<00:00, 34.20it/s]\n",
      "2022-12-31 09:38:48.257 | INFO     | src.models.train_model:trainloop:171 - Epoch 3 train 0.2870 test 0.3483 metric ['0.8712']\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 33.86it/s]\n",
      "2022-12-31 09:39:45.643 | INFO     | src.models.train_model:trainloop:171 - Epoch 4 train 0.2686 test 0.3208 metric ['0.8875']\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 33.87it/s]\n",
      "2022-12-31 09:40:42.973 | INFO     | src.models.train_model:trainloop:171 - Epoch 5 train 0.2468 test 0.3403 metric ['0.8862']\n",
      "100%|██████████| 1875/1875 [00:54<00:00, 34.17it/s]\n",
      "2022-12-31 09:41:39.802 | INFO     | src.models.train_model:trainloop:171 - Epoch 6 train 0.2321 test 0.3098 metric ['0.8871']\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 33.99it/s]\n",
      "2022-12-31 09:42:36.996 | INFO     | src.models.train_model:trainloop:171 - Epoch 7 train 0.2182 test 0.2625 metric ['0.9081']\n",
      "100%|██████████| 1875/1875 [00:55<00:00, 34.02it/s]\n",
      "2022-12-31 09:43:34.204 | INFO     | src.models.train_model:trainloop:171 - Epoch 8 train 0.2078 test 0.3155 metric ['0.8954']\n",
      "  1%|          | 19/1875 [00:00<00:52, 35.59it/s]\n",
      " 90%|█████████ | 9/10 [08:35<00:57, 57.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fil_range_e3 \u001b[39m=\u001b[39m [\u001b[39m16\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m]\n\u001b[1;32m      2\u001b[0m fil_range_e10 \u001b[39m=\u001b[39m [\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m hand_hypertuning(\n\u001b[1;32m      5\u001b[0m     model_dic \u001b[39m=\u001b[39;49m model_dic[\u001b[39m'\u001b[39;49m\u001b[39mCNN_150\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m     ,learning_rates \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m\n\u001b[1;32m      7\u001b[0m     ,kernel_sizes \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     ,filters1 \u001b[39m=\u001b[39;49m fil_range_e10\n\u001b[1;32m      9\u001b[0m     ,filters2 \u001b[39m=\u001b[39;49m fil_range_e10\n\u001b[1;32m     10\u001b[0m     ,units1 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     11\u001b[0m     ,units2 \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m\n\u001b[1;32m     12\u001b[0m     ,log_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../../models/filters_cnn150/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m     ,epoch \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m\n\u001b[1;32m     14\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m, in \u001b[0;36mhand_hypertuning\u001b[0;34m(learning_rates, kernel_sizes, filters1, filters2, units1, units2, model_dic, epoch, num_classes, log_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[39m# print(gin.config_str())\u001b[39;00m\n\u001b[1;32m     71\u001b[0m                                 model \u001b[39m=\u001b[39m model_dic[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m                                 model \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     74\u001b[0m                                     model\u001b[39m=\u001b[39;49mmodel(),\n\u001b[1;32m     75\u001b[0m                                     metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     76\u001b[0m                                     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     77\u001b[0m                                     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     78\u001b[0m                                     train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     79\u001b[0m                                     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     80\u001b[0m                                 )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry_add_pandas-Tn0MmM9i-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:146\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    143\u001b[0m     writer\u001b[39m.\u001b[39madd_graph(model, images)\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 146\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    147\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    151\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/code/ml22_klein/dev/notebooks/../../src/models/train_model.py:41\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_loss: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(train_steps)):\n\u001b[0;32m---> 41\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(traindatastreamer))\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fil_range_e3 = [16,32,64,128]\n",
    "fil_range_e10 = [32,64]\n",
    "\n",
    "hand_hypertuning(\n",
    "    model_dic = model_dic['CNN_150']\n",
    "    ,learning_rates = 0.001\n",
    "    ,kernel_sizes = 2\n",
    "    ,filters1 = fil_range_e10\n",
    "    ,filters2 = fil_range_e10\n",
    "    ,units1 = 128\n",
    "    ,units2 = 128\n",
    "    ,log_dir = \"../../models/filters_cnn150/\"\n",
    "    ,epoch = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('poetry_add_pandas-Tn0MmM9i-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Nov 19 2022, 09:58:14) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc99aa1bd7537e0258e13e20cc216861e02369acc2d56ce5faa223331cf95d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
